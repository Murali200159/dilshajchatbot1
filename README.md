<<<<<<< HEAD
 #Dilshaj Infotech AI Assistant
=======
# Dilshaj Infotech AI Assistant
>>>>>>> fbfe22fd (Added antigravity modifications and EC2 updates)

A production-ready, single-agent conversational AI system designed to handle company inquiries, user data retrieval, and general chat. Powered by **LLaMA 3 (via Ollama)**, **LangGraph**, **FastAPI**, and **MongoDB**.

## ğŸš€ Key Features

*   **Single Agent Router Architecture**: Intelligently routes user queries to specific tools or handles them directly via LLM.
*   **Offline Capability**: Entirely self-hosted using **Ollama** and **Local LLMs** (no API keys required!).
*   **Vector Search (RAG)**: Retrieves answers from local company documents (PDF/MD) using FAISS and Ollama Embeddings.
*   **Direct Database Access**: Queries **MongoDB** for real-time user data (e.g., payment status, profiles).
*   **Memory Persistence**: Remembers previous turns in the conversation using MongoDB-backed Checkpointing.
*   **Fine-Tuning Support**: Includes scripts to fine-tune LLaMA on your own custom dataset and load it dynamically.
*   **Production Ready**: Dockerized, async-optimized, and includes comprehensive logging/monitoring hooks.

---

## ğŸ› ï¸ Technology Stack

*   **Brain**: LLaMA 3 (Default) / Custom Fine-Tuned Models (Adapter Support).
*   **Orchestration**: LangGraph + LangChain.
*   **Backend**: FastAPI (Python 3.10+).
*   **Database**: MongoDB (User Data & Chat History).
*   **Knowledge Base**: FAISS (Local Vector Store).
*   **Frontend**: Static HTML5/JS (Lightweight Web Chat).
*   **Serving**: Uvicorn / Docker.

---

## ğŸ“‚ Project Structure

```bash
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/          # FastAPI Routes (/chat/stream, /health)
â”‚   â”œâ”€â”€ core/         # Config, Logging, LangGraph Definition
â”‚   â”œâ”€â”€ services/     # LLM (Ollama/Transformers), Database, Memory
â”‚   â””â”€â”€ tools/        # RAG Tool, User Data Tool
â”œâ”€â”€ data/
â”‚   â””â”€â”€ company_docs/ # Place your Markdown/PDF policies here
â”œâ”€â”€ training/         # LLaMA 3 Fine-Tuning Scripts (LoRA/QLoRA)
â”œâ”€â”€ static/           # Web Chat Interface (HTML/CSS/JS)
â”œâ”€â”€ tests/            # Pytest Suite
â””â”€â”€ docker-compose.yml
<<<<<<< HEAD
```

---

## âš¡ Quick Start

### 1. Prerequisites
*   Python 3.10+
*   [Ollama](https://ollama.com/) installed and running (`ollama serve`).
*   MongoDB running locally or in Docker.

### 2. Installation
```bash
# Clone the repo
git clone https://github.com/your-repo/dilshaj-ai-agent.git
cd dilshaj-ai-agent

# Create Virtual Environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install Dependencies
pip install -r requirements.txt
pip install -e .
```

### 3. Configuration
Copy `.env.example` to `.env` and configure:
```ini
# .env
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=dilshaj-ai
MONGO_URI=mongodb://localhost:27017
MONGO_DB_NAME=dilshaj_db
```

### 4. Populate Data (Optional)
This script creates dummy users and indexes your `data/company_docs`.
```bash
python scripts/populate_db.py
python scripts/reindex_rag.py
```

### 5. Run the Application
```bash
# Start backend server
python -m uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```
Visit **http://localhost:8000/static/index.html** to chat!

---

## ğŸ“ Training (Fine-Tuning)

You can fine-tune LLaMA on your own data using the `training/` module.

1.  Place your dataset (JSON) in `training/`.
2.  Run:
    ```bash
    python training/train_lora.py --dataset_path "my_data.json" --new_model_name "my-custom-model"
    ```
3.  Deploy: Set `USE_FINETUNED_MODEL=true` in `.env`.

---

## ğŸ³ Docker Deployment

To run everything in containers:
```bash
docker-compose up --build
```

---

## â˜ï¸ AWS EC2 Deployment (GPU)

See `DEPLOYMENT_EC2_GPU.md` for detailed instructions on running with NVIDIA GPUs (T4/A10G).

---

## ğŸ“ License
Proprietary / MIT (Edit as needed).

```
fastapi-langgraph-agent-production-ready-template-master/
â”œâ”€â”€ app/                        # ğŸ§  The Main Application Code
â”‚   â”œâ”€â”€ api/                    # ğŸŒ REST API Endpoints (FastAPI)
â”‚   â”‚   â””â”€â”€ v1/                 # Version 1 API routes
â”‚   â”‚       â”œâ”€â”€ api.py          # Main Router (collects all routes)
â”‚   â”‚       â””â”€â”€ chatbot.py      # The /chat/stream endpoint (Frontend talks to this!)
â”‚   â”œâ”€â”€ core/                   # âš™ï¸ Core Configuration & Logic
â”‚   â”‚   â”œâ”€â”€ config.py           # Application Settings (reads .env)
â”‚   â”‚   â”œâ”€â”€ logging.py          # Custom Logger Setup
â”‚   â”‚   â”œâ”€â”€ langgraph/          # ğŸ¤– The AI Brain (LangGraph)
â”‚   â”‚   â”‚   â”œâ”€â”€ graph.py        # Defines the Workflow (User -> Tool -> Agent)
â”‚   â”‚   â”‚   â””â”€â”€ state.py        # Defines what data the agent remembers per turn
â”‚   â”‚   â””â”€â”€ prompts/            # ğŸ“ AI Prompts (System Instructions)
â”‚   â”‚       â””â”€â”€ system.md       # The "Persona" of the AI (You are Dilshaj AI...)
â”‚   â”œâ”€â”€ services/               # ğŸ”Œ Integrations with External Services
â”‚   â”‚   â”œâ”€â”€ llm.py              # Manages Ollama / Local Fine-Tuned Model
â”‚   â”‚   â”œâ”€â”€ database.py         # Manages MongoDB Connection
â”‚   â”‚   â””â”€â”€ memory.py           # Handles Conversation History (Checkpointer)
â”‚   â”œâ”€â”€ tools/                  # ğŸ› ï¸ capabilities (The "Hands" of the AI)
â”‚   â”‚   â”œâ”€â”€ rag/                # Retrieval Augmented Generation (Company Docs)
â”‚   â”‚   â””â”€â”€ user_details/       # MongoDB User/Payment Lookup Tool
â”‚   â””â”€â”€ main.py                 # ğŸš€ Entry Point (Starts the FastAPI server)
â”‚
â”œâ”€â”€ data/                       # ğŸ—„ï¸ Local Data Storage
â”‚   â””â”€â”€ company_docs/           # ğŸ“„ Place your PDFs/MDs here (Policies, Info)
â”‚       â”œâ”€â”€ refund_policy.md
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ static/                     # ğŸ¨ Frontend (HTML/JS/CSS)
â”‚   â”œâ”€â”€ index.html              # The Chat Interface
â”‚   â”œâ”€â”€ style.css
â”‚   â””â”€â”€ script.js
â”‚
â”œâ”€â”€ training/                   # ğŸ“ Fine-Tuning Module
â”‚   â”œâ”€â”€ train_lora.py           # Script to train custom LLaMA models
â”‚   â””â”€â”€ requirements.txt        # Dependencies for training
â”‚
â”œâ”€â”€ tests/                      # ğŸ§ª Automated Tests
â”‚   â”œâ”€â”€ test_agent_final.py     # Tests the full agent flow
â”‚   â””â”€â”€ test_rag_file.py        # Tests document retrieval
â”‚
â”œâ”€â”€ scripts/                    # ğŸ“œ Utility Scripts
â”‚   â”œâ”€â”€ populate_db.py          # Fills MongoDB with dummy user data
â”‚   â””â”€â”€ reindex_rag.py          # Rebuilds the FAISS index from 'data/company_docs'
â”‚
â”œâ”€â”€ .env                        # ğŸ”‘ Environment Variables (Secrets, Configs)
â”œâ”€â”€ docker-compose.yml          # ğŸ³ Container Orchestration
â”œâ”€â”€ pyproject.toml              # ğŸ“¦ Python Dependencies (Poetry style)
â”œâ”€â”€ Makefile                    # âš¡ Shortcuts (make run, make test)
â””â”€â”€ DEPLOYMENT_EC2_GPU.md       # ğŸ“– Deployment Guide for AWS
=======
>>>>>>> fbfe22fd (Added antigravity modifications and EC2 updates)
```

---

## âš¡ Quick Start

### 1. Prerequisites
*   Python 3.10+
*   [Ollama](https://ollama.com/) installed and running (`ollama serve`).
*   MongoDB running locally or in Docker.

### 2. Installation
```bash
# Clone the repo
git clone https://github.com/your-repo/dilshaj-ai-agent.git
cd dilshaj-ai-agent

# Create Virtual Environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install Dependencies
pip install -r requirements.txt
pip install -e .
```

### 3. Configuration
Copy `.env.example` to `.env` and configure:
```ini
# .env
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=dilshaj-ai
MONGO_URI=mongodb://localhost:27017
MONGO_DB_NAME=dilshaj_db
```

### 4. Populate Data (Optional)
This script creates dummy users and indexes your `data/company_docs`.
```bash
python scripts/populate_db.py
python scripts/reindex_rag.py
```

### 5. Run the Application
```bash
# Start backend server
python -m uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```
Visit **http://localhost:8000/static/index.html** to chat!

---

## ğŸ“ Training (Fine-Tuning)

You can fine-tune LLaMA on your own data using the `training/` module.

1.  Place your dataset (JSON) in `training/`.
2.  Run:
    ```bash
    python training/train_lora.py --dataset_path "my_data.json" --new_model_name "my-custom-model"
    ```
3.  Deploy: Set `USE_FINETUNED_MODEL=true` in `.env`.

---

## ğŸ³ Docker Deployment

To run everything in containers:
```bash
docker-compose up --build
```

---

## â˜ï¸ AWS EC2 Deployment (GPU)

See `DEPLOYMENT_EC2_GPU.md` for detailed instructions on running with NVIDIA GPUs (T4/A10G).

---

## ğŸ“ License
Proprietary / MIT (Edit as needed).
